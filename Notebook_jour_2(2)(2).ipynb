{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YySiGfQ1SNwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cff0866-8ff3-4675-9364-f6e13f2e4f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0rq6fLsSSPUn"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "DATA_PATH = '/content/drive/MyDrive/ST_EI/data' \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import string\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "x2uxsPm48TCD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kiMuicy6Du8"
      },
      "source": [
        "**Important :**\n",
        "\n",
        "An Excel file for testing the evaluation part is available in the gitlab repo : evaluation_search_engine_post_queries_ranking_EI_CS.xlsx\n",
        "\n",
        "If you work on Colab, we advice you to push it directly on your Google Drive directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arfKMWtLyyxY"
      },
      "source": [
        "# Evaluate the Search\n",
        "\n",
        "Now you implement multiple search methods and you're able to improve it. You have to define metric to compare it objectively.\n",
        "\n",
        "\n",
        "\n",
        "We ask you to implement NDCG (Normalized Discounted Cumulative Gain) from few queries we implement on a dozen of post. We already defined the values of relevance judgement in the xlsx file : . The final score will be the mean quadratic error of the queries.\n",
        "\n",
        "\n",
        "Explication for the xlsx file :\n",
        "\n",
        "We propose you a Excel file with some posts and a mesure of relevancy for the queries\n",
        "\n",
        "- First column is the post Id,\n",
        "- Columns starting by query are the queries you have to test.\n",
        "- The values in this columns are the rank of relevancy of the post in regard with the query.\n",
        "- The missing values indicates you should not take into account the post\n",
        "\n",
        "\n",
        "You will have to criticize this metric and your result in the report. Then you will have to propose some improvements. \n",
        "\n",
        "Thereafter in this week, you will have to compare your different search engines."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n",
        "\n",
        "def remove_tags(text:str)->str:\n",
        "  # TODO\n",
        "  res = text.replace('<p>',' ').replace('</p>',' ').replace('<\\t>',' ').replace('\\n',' ').strip()\n",
        "  return res\n",
        "\n",
        "clean_posts = posts[['Id','Body']]\n",
        "clean_posts['cleaned_body'] = clean_posts['Body'].fillna('').apply(remove_tags)\n",
        "\n",
        "\n",
        "def extract_words(text:str)->list:\n",
        "  #enlever les majuscules\n",
        "  text = text.lower()\n",
        "\n",
        "  #enlever les ponctuations\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  liste = text.split(' ')\n",
        "  liste = list(set(liste))\n",
        "  if '' in liste :\n",
        "    liste.remove('')\n",
        "\n",
        "  return liste\n",
        "\n",
        "clean_posts['words'] = clean_posts['cleaned_body'].apply(extract_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWwUfu9S89At",
        "outputId": "755c1f12-7924-432f-acf6-0b1407eea388"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-6fa7291e6ee7>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_posts['cleaned_body'] = clean_posts['Body'].fillna('').apply(remove_tags)\n",
            "<ipython-input-69-6fa7291e6ee7>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_posts['words'] = clean_posts['cleaned_body'].apply(extract_words)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZxCcftBPagMQ"
      },
      "outputs": [],
      "source": [
        "# Read Relevancy CSV\n",
        "df_relevancy = pd.read_excel(\"/content/drive/MyDrive/ST_EI/data/evaluation_search_engine_post_queries_ranking_EI_CS.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df_relevancy,clean_posts, left_on='PostId', right_on='Id')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yBSJjIgy81KJ",
        "outputId": "4130412c-0bf5-4f97-9623-2da3e0fb85c3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    PostId                                              Title  \\\n",
              "0     6107                   What are deconvolutional layers?   \n",
              "1    15989  Micro Average vs Macro average Performance in ...   \n",
              "2    13490  How to set class weights for imbalanced classe...   \n",
              "3    12321  What's the difference between fit and fit_tran...   \n",
              "4       22  K-Means clustering for mixed numeric and categ...   \n",
              "5    14899  How to draw Deep learning network architecture...   \n",
              "6     5706  What is the \"dying ReLU\" problem in neural net...   \n",
              "7    15135     Train/Test/Validation Set Splitting in Sklearn   \n",
              "8    12851  How do you visualize neural network architectu...   \n",
              "9      694            Best python library for neural networks   \n",
              "10    9302  The cross-entropy error function in neural net...   \n",
              "11    9443  When to use One Hot Encoding vs LabelEncoder v...   \n",
              "\n",
              "                                       First Sentence  \\\n",
              "0   I recently read Fully Convolutional Networks f...   \n",
              "1   I am trying out a multiclass classification se...   \n",
              "2   I know that there is a possibility in Keras wi...   \n",
              "3   I do not understand the difference between the...   \n",
              "4   My data set contains a number of numeric attri...   \n",
              "5                              I have built my model.   \n",
              "6   Referring to the Stanford course notes on Conv...   \n",
              "7   How could I randomly split a data matrix and t...   \n",
              "8   When writing a paper / making a presentation a...   \n",
              "9   I'm using Neural Networks to solve different M...   \n",
              "10  In the MNIST For ML Beginners they define cros...   \n",
              "11  I have been building models with categorical d...   \n",
              "\n",
              "    Query 1 : mesure performance for multiclassification model  \\\n",
              "0                                                 NaN            \n",
              "1                                                 2.0            \n",
              "2                                                 1.0            \n",
              "3                                                 NaN            \n",
              "4                                                 NaN            \n",
              "5                                                 NaN            \n",
              "6                                                 NaN            \n",
              "7                                                 NaN            \n",
              "8                                                 NaN            \n",
              "9                                                 NaN            \n",
              "10                                                NaN            \n",
              "11                                                NaN            \n",
              "\n",
              "    Query 2 : draw neural network  Query 3 : neural network layers  \\\n",
              "0                             NaN                              6.0   \n",
              "1                             NaN                              NaN   \n",
              "2                             NaN                              NaN   \n",
              "3                             NaN                              NaN   \n",
              "4                             NaN                              NaN   \n",
              "5                             4.0                              2.0   \n",
              "6                             2.0                              5.0   \n",
              "7                             NaN                              NaN   \n",
              "8                             5.0                              3.0   \n",
              "9                             3.0                              4.0   \n",
              "10                            1.0                              1.0   \n",
              "11                            NaN                              NaN   \n",
              "\n",
              "    Query 4 : how sklearn working  Query 5 : treat categorical data     Id  \\\n",
              "0                             NaN                               NaN   6107   \n",
              "1                             NaN                               NaN  15989   \n",
              "2                             NaN                               NaN  13490   \n",
              "3                             7.0                               2.0  12321   \n",
              "4                             3.0                               3.0     22   \n",
              "5                             NaN                               NaN  14899   \n",
              "6                             NaN                               NaN   5706   \n",
              "7                             6.0                               NaN  15135   \n",
              "8                             NaN                               NaN  12851   \n",
              "9                             5.0                               NaN    694   \n",
              "10                            4.0                               1.0   9302   \n",
              "11                            1.0                               4.0   9443   \n",
              "\n",
              "                                                 Body  \\\n",
              "0   <p>I recently read <a href=\"http://arxiv.org/a...   \n",
              "1   <p>I am trying out a multiclass classification...   \n",
              "2   <p>I know that there is a possibility in Keras...   \n",
              "3   <p>I do not understand the difference between ...   \n",
              "4   <p>My data set contains a number of numeric at...   \n",
              "5   <p>I have built my model. Now I want to draw t...   \n",
              "6   <p>Referring to the Stanford course notes on <...   \n",
              "7   <p>How could I randomly split a data matrix an...   \n",
              "8   <p>When writing a paper / making a presentatio...   \n",
              "9   <p>I'm using Neural Networks to solve differen...   \n",
              "10  <p>In the <a href=\"https://www.tensorflow.org/...   \n",
              "11  <p>I have been building models with categorica...   \n",
              "\n",
              "                                         cleaned_body  \\\n",
              "0   I recently read <a href=\"http://arxiv.org/abs/...   \n",
              "1   I am trying out a multiclass classification se...   \n",
              "2   I know that there is a possibility in Keras wi...   \n",
              "3   I do not understand the difference between the...   \n",
              "4   My data set contains a number of numeric attri...   \n",
              "5   I have built my model. Now I want to draw the ...   \n",
              "6   Referring to the Stanford course notes on <a h...   \n",
              "7   How could I randomly split a data matrix and t...   \n",
              "8   When writing a paper / making a presentation a...   \n",
              "9   I'm using Neural Networks to solve different M...   \n",
              "10  In the <a href=\"https://www.tensorflow.org/ver...   \n",
              "11  I have been building models with categorical d...   \n",
              "\n",
              "                                                words  \n",
              "0   [called, understanding, 42, lossbr, my, layers...  \n",
              "1   [dataset, equal, codepre, precode, a, distribu...  \n",
              "2   [a, in, would, kind, fitting, weight, find, co...  \n",
              "3   [categorical, numbers, codefittransformcode, w...  \n",
              "4   [categorical, three, my, iscategoricalattrvalu...  \n",
              "5   [architecture, research, hrefhttpsistackimgurc...  \n",
              "6   [happens, proper, your, issue, activate, entir...  \n",
              "7   [codeytestcode, two, three, a, could, data, co...  \n",
              "8   [architecture, when, a, presentation, networks...  \n",
              "9   [networks, a, in, library, this, and, problems...  \n",
              "10  [value, give, obvious, beginnersa, crossentrop...  \n",
              "11  [me, categorical, scikitlearns, terms, when, b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f515d89-592f-4f95-a957-699d8387885a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PostId</th>\n",
              "      <th>Title</th>\n",
              "      <th>First Sentence</th>\n",
              "      <th>Query 1 : mesure performance for multiclassification model</th>\n",
              "      <th>Query 2 : draw neural network</th>\n",
              "      <th>Query 3 : neural network layers</th>\n",
              "      <th>Query 4 : how sklearn working</th>\n",
              "      <th>Query 5 : treat categorical data</th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>cleaned_body</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6107</td>\n",
              "      <td>What are deconvolutional layers?</td>\n",
              "      <td>I recently read Fully Convolutional Networks f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6107</td>\n",
              "      <td>&lt;p&gt;I recently read &lt;a href=\"http://arxiv.org/a...</td>\n",
              "      <td>I recently read &lt;a href=\"http://arxiv.org/abs/...</td>\n",
              "      <td>[called, understanding, 42, lossbr, my, layers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15989</td>\n",
              "      <td>Micro Average vs Macro average Performance in ...</td>\n",
              "      <td>I am trying out a multiclass classification se...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15989</td>\n",
              "      <td>&lt;p&gt;I am trying out a multiclass classification...</td>\n",
              "      <td>I am trying out a multiclass classification se...</td>\n",
              "      <td>[dataset, equal, codepre, precode, a, distribu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13490</td>\n",
              "      <td>How to set class weights for imbalanced classe...</td>\n",
              "      <td>I know that there is a possibility in Keras wi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13490</td>\n",
              "      <td>&lt;p&gt;I know that there is a possibility in Keras...</td>\n",
              "      <td>I know that there is a possibility in Keras wi...</td>\n",
              "      <td>[a, in, would, kind, fitting, weight, find, co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12321</td>\n",
              "      <td>What's the difference between fit and fit_tran...</td>\n",
              "      <td>I do not understand the difference between the...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12321</td>\n",
              "      <td>&lt;p&gt;I do not understand the difference between ...</td>\n",
              "      <td>I do not understand the difference between the...</td>\n",
              "      <td>[categorical, numbers, codefittransformcode, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22</td>\n",
              "      <td>K-Means clustering for mixed numeric and categ...</td>\n",
              "      <td>My data set contains a number of numeric attri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>&lt;p&gt;My data set contains a number of numeric at...</td>\n",
              "      <td>My data set contains a number of numeric attri...</td>\n",
              "      <td>[categorical, three, my, iscategoricalattrvalu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14899</td>\n",
              "      <td>How to draw Deep learning network architecture...</td>\n",
              "      <td>I have built my model.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14899</td>\n",
              "      <td>&lt;p&gt;I have built my model. Now I want to draw t...</td>\n",
              "      <td>I have built my model. Now I want to draw the ...</td>\n",
              "      <td>[architecture, research, hrefhttpsistackimgurc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5706</td>\n",
              "      <td>What is the \"dying ReLU\" problem in neural net...</td>\n",
              "      <td>Referring to the Stanford course notes on Conv...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5706</td>\n",
              "      <td>&lt;p&gt;Referring to the Stanford course notes on &lt;...</td>\n",
              "      <td>Referring to the Stanford course notes on &lt;a h...</td>\n",
              "      <td>[happens, proper, your, issue, activate, entir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15135</td>\n",
              "      <td>Train/Test/Validation Set Splitting in Sklearn</td>\n",
              "      <td>How could I randomly split a data matrix and t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15135</td>\n",
              "      <td>&lt;p&gt;How could I randomly split a data matrix an...</td>\n",
              "      <td>How could I randomly split a data matrix and t...</td>\n",
              "      <td>[codeytestcode, two, three, a, could, data, co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12851</td>\n",
              "      <td>How do you visualize neural network architectu...</td>\n",
              "      <td>When writing a paper / making a presentation a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12851</td>\n",
              "      <td>&lt;p&gt;When writing a paper / making a presentatio...</td>\n",
              "      <td>When writing a paper / making a presentation a...</td>\n",
              "      <td>[architecture, when, a, presentation, networks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>694</td>\n",
              "      <td>Best python library for neural networks</td>\n",
              "      <td>I'm using Neural Networks to solve different M...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>694</td>\n",
              "      <td>&lt;p&gt;I'm using Neural Networks to solve differen...</td>\n",
              "      <td>I'm using Neural Networks to solve different M...</td>\n",
              "      <td>[networks, a, in, library, this, and, problems...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9302</td>\n",
              "      <td>The cross-entropy error function in neural net...</td>\n",
              "      <td>In the MNIST For ML Beginners they define cros...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9302</td>\n",
              "      <td>&lt;p&gt;In the &lt;a href=\"https://www.tensorflow.org/...</td>\n",
              "      <td>In the &lt;a href=\"https://www.tensorflow.org/ver...</td>\n",
              "      <td>[value, give, obvious, beginnersa, crossentrop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>9443</td>\n",
              "      <td>When to use One Hot Encoding vs LabelEncoder v...</td>\n",
              "      <td>I have been building models with categorical d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9443</td>\n",
              "      <td>&lt;p&gt;I have been building models with categorica...</td>\n",
              "      <td>I have been building models with categorical d...</td>\n",
              "      <td>[me, categorical, scikitlearns, terms, when, b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f515d89-592f-4f95-a957-699d8387885a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f515d89-592f-4f95-a957-699d8387885a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f515d89-592f-4f95-a957-699d8387885a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = {1:'mesure performance for multiclassification model',2:'draw neural network',3:'neural network layers',4:'how sklearn working',5:'treat categorical data'}"
      ],
      "metadata": {
        "id": "M049yGkc8YFk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FVxld-Ujy0nN"
      },
      "outputs": [],
      "source": [
        "def classement(liste):\n",
        "  #input : liste\n",
        "  #output : liste\n",
        "\n",
        "  classement_parfait = []\n",
        "\n",
        "  #remplacer les NaN par des 0\n",
        "  for elem in liste:\n",
        "    if elem >=0 :\n",
        "      classement_parfait.append(elem)\n",
        "    else :\n",
        "      classement_parfait.append(0)\n",
        "\n",
        "  return classement_parfait\n",
        "\n",
        "def dg(x,k):\n",
        "  return x/np.log2(k+1)\n",
        "\n",
        "\n",
        "def calculate_ndgc(query_nb, out, df=df, queries=queries):\n",
        "  # out : liste des docs_id renvoyée par le modèle en ordre décroissant d'importance (index 0 = doc le plus pertinent)\n",
        "  \n",
        "  # calcul du dgc du classement parfait\n",
        "  liste = list(df['Query '+str(query_nb)+' : '+str(queries[query_nb])])\n",
        "  classement_parfait = classement(liste)\n",
        "  classement_parfait.sort(reverse = True)\n",
        "  classement_parfait_dg = [dg(classement_parfait[i],i+1) for i in range (len(classement_parfait))]\n",
        "  newlist = []\n",
        "  for i in range(len(classement_parfait_dg)):\n",
        "    newlist.append(sum(classement_parfait_dg[:i+1]))\n",
        "\n",
        "\n",
        "  # calcul du dgc du classement du modèle\n",
        "  classement_model = classement(out)\n",
        "  classement_model_dg = [dg(classement_model[i],i+1) for i in range (len(classement_model))]\n",
        "  newlist2 = []\n",
        "  for i in range(len(classement_model_dg)):\n",
        "    newlist2.append(sum(classement_model_dg[:i+1]))\n",
        "  \n",
        "  # calcul du ndgc\n",
        "  res = [newlist2[i]/newlist[i] for i in range (len(newlist))]\n",
        "  \n",
        "\n",
        "  return res[-1]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSrHXC3GAGPG"
      },
      "source": [
        "# Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METHODE NAIVE"
      ],
      "metadata": {
        "id": "2O5_mFQJAcwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def word_in_index(word, word_list_index):\n",
        "  if word in word_list_index:\n",
        "    res = pd.Series([1])\n",
        "  else :\n",
        "    res = pd.Series([0])\n",
        "  return res\n",
        "\n",
        "def count_common_words(query, word_serie):\n",
        "  # TODO\n",
        "  res = pd.Series([0])\n",
        "  requete = extract_words(query)\n",
        "  for word in requete:\n",
        "    res = res.add(word_in_index(word,word_serie))\n",
        "  return res\n",
        "\n",
        "def rank_top_query(query, df, top=5):\n",
        "  # TODO\n",
        "  nb_of_common_words = pd.Series([])\n",
        "  for i in df.index:\n",
        "    nb_of_common_words = pd.concat([nb_of_common_words,count_common_words(query,df['words'][i])], ignore_index = True)\n",
        "  df['Common words with query'] = nb_of_common_words\n",
        "  newdf = df.sort_values(by='Common words with query', ascending = False)\n",
        "  res = newdf.head(top)\n",
        "  return res"
      ],
      "metadata": {
        "id": "wAfxcfvlAN5z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1 = list(rank_top_query(query=\"mesure performance for multiclassification model\", df=df, top=12)['Query 1 : mesure performance for multiclassification model'])\n",
        "out2 = list(rank_top_query(query=\"draw neural network\", df=df, top=12)['Query 2 : draw neural network'])\n",
        "out3 = list(rank_top_query(query=\"neural network layers\", df=df, top=12)['Query 3 : neural network layers'])\n",
        "out4 = list(rank_top_query(query=\"how sklearn working\", df=df, top=12)['Query 4 : how sklearn working'])\n",
        "out5 = list(rank_top_query(query=\"treat categorical data\", df=df, top=12)['Query 5 : treat categorical data'])\n",
        "\n",
        "\n",
        "ndgc = [calculate_ndgc(1,out1),calculate_ndgc(2,out2),calculate_ndgc(3,out3),calculate_ndgc(4,out4),calculate_ndgc(5,out5)]\n",
        "print(ndgc)\n",
        "\n",
        "print(np.mean(ndgc))"
      ],
      "metadata": {
        "id": "oJPWi0aVBKDB",
        "outputId": "32cd5d43-219d-4782-f790-e160606f54d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3852038879047554, 0.9190820655219575, 0.9561477088560267, 0.6622661640221295, 0.841545187434471]\n",
            "0.752849002747868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-38c03c59c5ee>:32: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  nb_of_common_words = pd.Series([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METHODE PROBABILISTE"
      ],
      "metadata": {
        "id": "Q-Xv2RV1Dz3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank-bm25"
      ],
      "metadata": {
        "id": "8N2YY9-pD6gy",
        "outputId": "b19fd01d-639d-4993-9174-bdc7650271bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank-bm25) (1.22.4)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "k-LTknRbECn7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        " \n",
        "nltk.download('stopwords')\n",
        "liste_stop_words = stopwords.words('english')\n",
        "print(liste_stop_words)"
      ],
      "metadata": {
        "id": "hljj3-MoEXVA",
        "outputId": "539e463c-4908-4c16-c10f-4a585523bc9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stop_words(l_txt: list) -> list:\n",
        "  newlist = []\n",
        "  for word in l_txt:\n",
        "    if word not in liste_stop_words:\n",
        "      newlist.append(word)\n",
        "\n",
        "  return newlist"
      ],
      "metadata": {
        "id": "kt-zvJ3zEW8N"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_words_remove_stop_words(text:str)->list:\n",
        "  #enlever les majuscules\n",
        "  text = text.lower()\n",
        "\n",
        "  #enlever les ponctuations\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  liste = text.split(' ')\n",
        "  liste = list(set(liste))\n",
        "  if '' in liste :\n",
        "    liste.remove('')\n",
        "\n",
        "  return remove_stop_words(liste)\n",
        "\n",
        "def probabilistic_search(query,df):\n",
        "  # TODO\n",
        "  corpus = []\n",
        "  index = []\n",
        "  for i in df.index:\n",
        "    corpus.append(df['words'][i])\n",
        "    index.append(df['Id'][i])\n",
        "  \n",
        "  bm25 = BM25Okapi(corpus)\n",
        "\n",
        "  tokenized_query = extract_words_remove_stop_words(query)\n",
        "\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  res = []\n",
        "  for i in range(len(index)):\n",
        "    res.append((index[i],doc_scores[i]))\n",
        "  res.sort(key = lambda x : x[1], reverse = True)\n",
        "  return res"
      ],
      "metadata": {
        "id": "px8sbHmMEG4W"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def traitement_search(search, query_nb):\n",
        "  liste = pd.Series([])\n",
        "  for i in range (len(search)):\n",
        "    liste = pd.concat([liste,df[df['PostId']==search[i][0]]['Query '+str(query_nb)+' : '+str(queries[query_nb])]], ignore_index = True)\n",
        "\n",
        "  return list(liste)"
      ],
      "metadata": {
        "id": "xxsFMohaEtAJ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search1 = traitement_search(probabilistic_search('mesure performance for multiclassification model',df),1)\n",
        "search2 = traitement_search(probabilistic_search('draw neural network',df),2)\n",
        "search3 = traitement_search(probabilistic_search('neural network layers',df),3)\n",
        "search4 = traitement_search(probabilistic_search('how sklearn working',df),4)\n",
        "search5 = traitement_search(probabilistic_search('treat categorical data',df),5)\n",
        "\n",
        "ndgc = [calculate_ndgc(1,search1),calculate_ndgc(2,search2),calculate_ndgc(3,search3),calculate_ndgc(4,search4),calculate_ndgc(5,search5)]\n",
        "print(ndgc)\n",
        "\n",
        "print(np.mean(ndgc))"
      ],
      "metadata": {
        "id": "E-zljDryD2jv",
        "outputId": "eed3a8b5-29b3-41ad-c6f5-b0a8ac38121d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8868854556705132, 0.9190820655219575, 0.8360196351516849, 0.5385410308781887, 0.841545187434471]\n",
            "0.8044146749313631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-b01caadd7a07>:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  liste = pd.Series([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METHODE VECTORIELLE"
      ],
      "metadata": {
        "id": "_DV3jWVeH4Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "JurON9ZQIGEQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vectorizer.fit(df.cleaned_body.values)\n",
        "\n",
        "vectors = vectorizer.transform(df.cleaned_body.values)"
      ],
      "metadata": {
        "id": "_7UXAiG7INoE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors"
      ],
      "metadata": {
        "id": "H7I3sLu8I1Hs",
        "outputId": "fa1fbb03-4abe-485a-adf5-4ee113e12770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<12x405 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 518 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_query(query : str, vectorizer=vectorizer):\n",
        "    \"\"\"vectorizes the query\n",
        "    Args:\n",
        "        query (str): query string\n",
        "        vectorizer (optional): Defaults to vectorizer.\n",
        "\n",
        "    Returns:\n",
        "        query vectorized\n",
        "    \"\"\"\n",
        "    #TODO\n",
        "    query_vectorized = vectorizer.transform([query]).toarray()\n",
        "\n",
        "    return query_vectorized"
      ],
      "metadata": {
        "id": "y3tnr0Q5IIqx"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def vectorizer_search(query : str, query_nb,\n",
        "                      vectors=vectors,\n",
        "                      vectorizer=vectorizer) -> list:\n",
        "    #TODO\n",
        "    vec_query = vectorize_query(query,vectorizer)\n",
        "    cos_sim = cosine_similarity(vec_query,vectors)[0]\n",
        "\n",
        "    #créer une liste de tuple (index du doc, similarité avec la requête)\n",
        "    sim = []\n",
        "    for i in range(len(cos_sim)):\n",
        "      sim.append((i,cos_sim[i]))\n",
        "    sim.sort(key = lambda x : x[1], reverse = True)\n",
        "\n",
        "    #retrouver les scores du top de similarité\n",
        "    res = []\n",
        "    for elem in sim:\n",
        "      text = df['Query '+str(query_nb)+' : '+str(queries[query_nb])][elem[0]]\n",
        "      res.append(text)\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "qA5OrEbzH6LQ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entry1 = vectorizer_search('mesure performance for multiclassification model',1)\n",
        "entry2 = vectorizer_search('draw neural network',2)\n",
        "entry3 = vectorizer_search('neural network layers',3)\n",
        "entry4 = vectorizer_search('how sklearn working',4)\n",
        "entry5 = vectorizer_search('treat categorical data',5)\n",
        "\n",
        "ndgc = [calculate_ndgc(1,entry1),calculate_ndgc(2,entry2),calculate_ndgc(3,entry3),calculate_ndgc(4,entry4),calculate_ndgc(5,entry5)]\n",
        "print(ndgc)\n",
        "\n",
        "print(np.mean(ndgc))"
      ],
      "metadata": {
        "id": "0mILrcxeI7IO",
        "outputId": "0b05c532-fd8a-43b9-f78e-30eee0116d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5067916889545789, 0.8502361767883351, 0.9948938993092976, 0.7998507326222158, 0.8310254998828857]\n",
            "0.7965595995114627\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}