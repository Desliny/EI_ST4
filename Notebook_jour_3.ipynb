{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DAY 3: Student version"
      ],
      "metadata": {
        "id": "Xycip-y7MmUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning NLP**\n",
        "\n",
        "The goal of this session is to improve the search engine using NLP features.\n",
        "\n",
        "This notebook guides you through different techniques to explore. It is expected of you to be inventive and improve the techniques introduced. \n",
        "\n",
        "First, let's import the useful packages and load the data."
      ],
      "metadata": {
        "id": "gnCKD6NtjZno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "tS0Nv3gMZw7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers --quiet"
      ],
      "metadata": {
        "id": "BU8SMVS4Zu0w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "TBamWPKlkZs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from scipy.sparse import find\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer "
      ],
      "metadata": {
        "id": "50KuGjmPjquG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a046015c-0478-4f61-cd54-21149e7d8ce4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "bVl7AEcBkgyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# TODO:\n",
        "DATA_PATH = '/content/drive/MyDrive/EI/data' \n",
        "\n",
        "# CORR:\n",
        "# DATA_PATH = '/content/drive/MyDrive/TP Centrale/data'\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVb0xZIvkevD",
        "outputId": "a3cdddd8-9a3c-447d-9e84-b6219e3af4c9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n",
        "posts"
      ],
      "metadata": {
        "id": "YBtfx_3RYSs9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54791015-b9f6-4c28-ba8f-f879de8a0036"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id  PostTypeId             CreationDate  Score  ViewCount  \\\n",
              "0           5           1  2014-05-13T23:58:30.457      9      898.0   \n",
              "1           7           1  2014-05-14T00:11:06.457      4      478.0   \n",
              "2           9           2  2014-05-14T00:36:31.077      5        NaN   \n",
              "3          10           2  2014-05-14T00:53:43.273     13        NaN   \n",
              "4          14           1  2014-05-14T01:25:59.677     26     1901.0   \n",
              "...       ...         ...                      ...    ...        ...   \n",
              "75722  119962           1  2023-03-04T20:06:06.820      0        8.0   \n",
              "75723  119963           1  2023-03-04T20:12:19.677      0       10.0   \n",
              "75724  119964           1  2023-03-05T00:14:12.597      0        7.0   \n",
              "75725  119965           1  2023-03-05T00:43:12.213      0        5.0   \n",
              "75726  119966           1  2023-03-05T03:10:27.593      0        2.0   \n",
              "\n",
              "                                                    Body  OwnerUserId  \\\n",
              "0      <p>I've always been interested in machine lear...          5.0   \n",
              "1      <p>As a researcher and instructor, I'm looking...         36.0   \n",
              "2      <p>Not sure if this fits the scope of this SE,...         51.0   \n",
              "3      <p>One book that's freely available is \"The El...         22.0   \n",
              "4      <p>I am sure data science as will be discussed...         66.0   \n",
              "...                                                  ...          ...   \n",
              "75722  <p>I am implementing a neural network of arbit...     147597.0   \n",
              "75723  <p>I am using KNN for a regression task</p>\\n<...     147598.0   \n",
              "75724  <p>I have developed a small encoding algorithm...      44581.0   \n",
              "75725  <p>To my understanding, optimizing a model wit...      84437.0   \n",
              "75726  <p>I'm working with a dataset of cars, contain...     147605.0   \n",
              "\n",
              "              LastActivityDate  \\\n",
              "0      2014-05-14T00:36:31.077   \n",
              "1      2014-05-16T13:45:00.237   \n",
              "2      2014-05-14T00:36:31.077   \n",
              "3      2014-05-14T00:53:43.273   \n",
              "4      2020-08-16T13:01:33.543   \n",
              "...                        ...   \n",
              "75722  2023-03-04T20:22:12.523   \n",
              "75723  2023-03-04T20:12:19.677   \n",
              "75724  2023-03-05T00:14:12.597   \n",
              "75725  2023-03-05T00:43:12.213   \n",
              "75726  2023-03-05T03:10:27.593   \n",
              "\n",
              "                                                   Title  \\\n",
              "0      How can I do simple machine learning without h...   \n",
              "1      What open-source books (or other materials) pr...   \n",
              "2                                                   None   \n",
              "3                                                   None   \n",
              "4               Is Data Science the Same as Data Mining?   \n",
              "...                                                  ...   \n",
              "75722  Back Propagation on arbitrary depth network wi...   \n",
              "75723                        Evaluation parameter in knn   \n",
              "75724  Can I use zero-padded input and output layers ...   \n",
              "75725  Why does cross validation and hyperparameter t...   \n",
              "75726                High metrics value (MAE, MSE, RMSE)   \n",
              "\n",
              "                                                    Tags  ...  \\\n",
              "0                                     <machine-learning>  ...   \n",
              "1                               <education><open-source>  ...   \n",
              "2                                                   None  ...   \n",
              "3                                                   None  ...   \n",
              "4                             <data-mining><definitions>  ...   \n",
              "...                                                  ...  ...   \n",
              "75722                  <neural-network><backpropagation>  ...   \n",
              "75723                                 <regression><k-nn>  ...   \n",
              "75724      <deep-learning><convolutional-neural-network>  ...   \n",
              "75725          <cross-validation><hyperparameter-tuning>  ...   \n",
              "75726  <python><pandas><machine-learning-model><linea...  ...   \n",
              "\n",
              "                    ClosedDate  ContentLicense AcceptedAnswerId  \\\n",
              "0      2014-05-14T14:40:25.950    CC BY-SA 3.0              NaN   \n",
              "1      2014-05-14T08:40:54.950    CC BY-SA 3.0             10.0   \n",
              "2                         None    CC BY-SA 3.0              NaN   \n",
              "3                         None    CC BY-SA 3.0              NaN   \n",
              "4                         None    CC BY-SA 3.0             29.0   \n",
              "...                        ...             ...              ...   \n",
              "75722                     None    CC BY-SA 4.0              NaN   \n",
              "75723                     None    CC BY-SA 4.0              NaN   \n",
              "75724                     None    CC BY-SA 4.0              NaN   \n",
              "75725                     None    CC BY-SA 4.0              NaN   \n",
              "75726                     None    CC BY-SA 4.0              NaN   \n",
              "\n",
              "      LastEditorUserId             LastEditDate  ParentId OwnerDisplayName  \\\n",
              "0                  NaN                     None       NaN             None   \n",
              "1                 97.0  2014-05-16T13:45:00.237       NaN             None   \n",
              "2                  NaN                     None       5.0             None   \n",
              "3                  NaN                     None       7.0             None   \n",
              "4                322.0  2014-06-17T16:17:20.473       NaN             None   \n",
              "...                ...                      ...       ...              ...   \n",
              "75722         147597.0  2023-03-04T20:22:12.523       NaN             None   \n",
              "75723              NaN                     None       NaN             None   \n",
              "75724              NaN                     None       NaN             None   \n",
              "75725              NaN                     None       NaN             None   \n",
              "75726              NaN                     None       NaN             None   \n",
              "\n",
              "       CommunityOwnedDate LastEditorDisplayName FavoriteCount  \n",
              "0                    None                  None           NaN  \n",
              "1                    None                  None           NaN  \n",
              "2                    None                  None           NaN  \n",
              "3                    None                  None           NaN  \n",
              "4                    None                  None           NaN  \n",
              "...                   ...                   ...           ...  \n",
              "75722                None                  None           NaN  \n",
              "75723                None                  None           NaN  \n",
              "75724                None                  None           NaN  \n",
              "75725                None                  None           NaN  \n",
              "75726                None                  None           NaN  \n",
              "\n",
              "[75727 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92282147-ff09-4fa5-9085-8ecd806450e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>PostTypeId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>Body</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>LastActivityDate</th>\n",
              "      <th>Title</th>\n",
              "      <th>Tags</th>\n",
              "      <th>...</th>\n",
              "      <th>ClosedDate</th>\n",
              "      <th>ContentLicense</th>\n",
              "      <th>AcceptedAnswerId</th>\n",
              "      <th>LastEditorUserId</th>\n",
              "      <th>LastEditDate</th>\n",
              "      <th>ParentId</th>\n",
              "      <th>OwnerDisplayName</th>\n",
              "      <th>CommunityOwnedDate</th>\n",
              "      <th>LastEditorDisplayName</th>\n",
              "      <th>FavoriteCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-13T23:58:30.457</td>\n",
              "      <td>9</td>\n",
              "      <td>898.0</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>How can I do simple machine learning without h...</td>\n",
              "      <td>&lt;machine-learning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>2014-05-14T14:40:25.950</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T00:11:06.457</td>\n",
              "      <td>4</td>\n",
              "      <td>478.0</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>What open-source books (or other materials) pr...</td>\n",
              "      <td>&lt;education&gt;&lt;open-source&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>2014-05-14T08:40:54.950</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>5.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>7.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T01:25:59.677</td>\n",
              "      <td>26</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2020-08-16T13:01:33.543</td>\n",
              "      <td>Is Data Science the Same as Data Mining?</td>\n",
              "      <td>&lt;data-mining&gt;&lt;definitions&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2014-06-17T16:17:20.473</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:06:06.820</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>Back Propagation on arbitrary depth network wi...</td>\n",
              "      <td>&lt;neural-network&gt;&lt;backpropagation&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>147598.0</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>Evaluation parameter in knn</td>\n",
              "      <td>&lt;regression&gt;&lt;k-nn&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>44581.0</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>Can I use zero-padded input and output layers ...</td>\n",
              "      <td>&lt;deep-learning&gt;&lt;convolutional-neural-network&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>84437.0</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>Why does cross validation and hyperparameter t...</td>\n",
              "      <td>&lt;cross-validation&gt;&lt;hyperparameter-tuning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>147605.0</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>High metrics value (MAE, MSE, RMSE)</td>\n",
              "      <td>&lt;python&gt;&lt;pandas&gt;&lt;machine-learning-model&gt;&lt;linea...</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75727 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92282147-ff09-4fa5-9085-8ecd806450e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92282147-ff09-4fa5-9085-8ecd806450e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92282147-ff09-4fa5-9085-8ecd806450e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "2q_ryLonxLYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a function to clean the posts. \n",
        "\n",
        "You can reuse what you have used in the Day 2 notebook or improve it."
      ],
      "metadata": {
        "id": "cnOIzOY4e5Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_post(text:str)->str:\n",
        "  res=\"\"\n",
        "  in_tag=False\n",
        "  next=False\n",
        "  for lettre in text:\n",
        "    if lettre=='<' and not in_tag:\n",
        "      in_tag=True\n",
        "    elif lettre=='>' and in_tag:\n",
        "      in_tag=False\n",
        "    elif lettre=='\\n' or lettre=='\\t':\n",
        "      next=True\n",
        "    elif not in_tag:\n",
        "      if next:\n",
        "        res+=\" \" + str(lettre)\n",
        "        next=False\n",
        "      else:\n",
        "        res+=str(lettre)\n",
        "  return res"
      ],
      "metadata": {
        "id": "9e-XxHMAkmEu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_posts = posts[['Id','Body']]\n",
        "clean_posts['Clean Body'] = clean_posts['Body'].fillna('').apply(clean_post)\n",
        "clean_posts"
      ],
      "metadata": {
        "id": "Yv_n2e5Y1a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "231dfe73-6b28-4413-8b71-002c75ea6743"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-f2d19e1d3215>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_posts['Clean Body'] = clean_posts['Body'].fillna('').apply(clean_post)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id                                               Body  \\\n",
              "0           5  <p>I've always been interested in machine lear...   \n",
              "1           7  <p>As a researcher and instructor, I'm looking...   \n",
              "2           9  <p>Not sure if this fits the scope of this SE,...   \n",
              "3          10  <p>One book that's freely available is \"The El...   \n",
              "4          14  <p>I am sure data science as will be discussed...   \n",
              "...       ...                                                ...   \n",
              "75722  119962  <p>I am implementing a neural network of arbit...   \n",
              "75723  119963  <p>I am using KNN for a regression task</p>\\n<...   \n",
              "75724  119964  <p>I have developed a small encoding algorithm...   \n",
              "75725  119965  <p>To my understanding, optimizing a model wit...   \n",
              "75726  119966  <p>I'm working with a dataset of cars, contain...   \n",
              "\n",
              "                                              Clean Body  \n",
              "0      I've always been interested in machine learnin...  \n",
              "1      As a researcher and instructor, I'm looking fo...  \n",
              "2      Not sure if this fits the scope of this SE, bu...  \n",
              "3      One book that's freely available is \"The Eleme...  \n",
              "4      I am sure data science as will be discussed in...  \n",
              "...                                                  ...  \n",
              "75722  I am implementing a neural network of arbitrar...  \n",
              "75723  I am using KNN for a regression task It's like...  \n",
              "75724  I have developed a small encoding algorithm th...  \n",
              "75725  To my understanding, optimizing a model with k...  \n",
              "75726  I'm working with a dataset of cars, containing...  \n",
              "\n",
              "[75727 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-167f7710-5d2d-4474-8d06-856bd6471bbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>Clean Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>I've always been interested in machine learnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>As a researcher and instructor, I'm looking fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>Not sure if this fits the scope of this SE, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>One book that's freely available is \"The Eleme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>I am sure data science as will be discussed in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>I am implementing a neural network of arbitrar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>I am using KNN for a regression task It's like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>I have developed a small encoding algorithm th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>To my understanding, optimizing a model with k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>I'm working with a dataset of cars, containing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75727 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-167f7710-5d2d-4474-8d06-856bd6471bbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-167f7710-5d2d-4474-8d06-856bd6471bbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-167f7710-5d2d-4474-8d06-856bd6471bbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also implement a function that cleans the user's query (the query). \n",
        "\n",
        "This step is optionnal (if you don't think that it is necessary, just return the query)"
      ],
      "metadata": {
        "id": "9vYfAFcDe_ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_query(text:str)->str:\n",
        "    cleaned_query = clean_post(text)\n",
        "    return cleaned_query"
      ],
      "metadata": {
        "id": "Q8_gvmjXwBwt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text specific metadata"
      ],
      "metadata": {
        "id": "BnjdSpeLlZzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What metadata can you get from the text at your disposal ? Which ones are relevant ? "
      ],
      "metadata": {
        "id": "qEyQEpoaoGLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "posts.keys()"
      ],
      "metadata": {
        "id": "5b_O0YS-oMAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a6da50-3dee-4d77-ea76-acf3645d6156"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'PostTypeId', 'CreationDate', 'Score', 'ViewCount', 'Body',\n",
              "       'OwnerUserId', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount',\n",
              "       'CommentCount', 'ClosedDate', 'ContentLicense', 'AcceptedAnswerId',\n",
              "       'LastEditorUserId', 'LastEditDate', 'ParentId', 'OwnerDisplayName',\n",
              "       'CommunityOwnedDate', 'LastEditorDisplayName', 'FavoriteCount'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classic Preprocessing"
      ],
      "metadata": {
        "id": "o0rsRxD4xeli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal for this part is to implement a classic vectorization (Count vectorizer, tfidf...).\n",
        "\n",
        "You can do it on your own or use scikit-learn.\n",
        "\n",
        "Hints : pay attention to stopwords, additionnal preprocessing steps and techniques of vectoriation\n"
      ],
      "metadata": {
        "id": "NLmg2T3qxjc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vectorizer.fit(clean_posts[\"Clean Body\"].values)\n",
        "vectors = vectorizer.transform(clean_posts[\"Clean Body\"].values)"
      ],
      "metadata": {
        "id": "VTaWk2nAAiTj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that applies the same process to the query\n"
      ],
      "metadata": {
        "id": "drg1x_9v1RD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_query(query : str, vectorizer=vectorizer):\n",
        "    \"\"\"vectorizes the query\n",
        "    Args:\n",
        "        query (str): query string\n",
        "        vectorizer (optional): Defaults to vectorizer.\n",
        "\n",
        "    Returns:\n",
        "        query vectorized\n",
        "    \"\"\"\n",
        "    query_clean=clean_query(query)\n",
        "    query_vectorized=vectorizer.transform([query_clean])\n",
        "    return query_vectorized"
      ],
      "metadata": {
        "id": "RpBr0mfF1QVr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity(vectors, vectorize_query(\"Test de l'EI\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWj_7Z-bycfE",
        "outputId": "8dc2d64f-f226-48b4-809a-4ace50ac6283"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.        ],\n",
              "       [0.        ],\n",
              "       ...,\n",
              "       [0.        ],\n",
              "       [0.12549116],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine a way to use this vectorization to suggest the closest items to the entry in the database"
      ],
      "metadata": {
        "id": "ZO5uBYas15HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def vectorizer_search(query : str,\n",
        "                      vectors=vectors,\n",
        "                      vectorizer=vectorizer,\n",
        "                      top=10) -> list:\n",
        "    query_vector=vectorize_query(query)\n",
        "    values=cosine_similarity(vectors, query_vector)\n",
        "    values=[[values[k][0],k] for k in range(len(values))]\n",
        "    values.sort(reverse=True)\n",
        "    closest_items = [clean_posts[\"Clean Body\"][x[1]] for x in values[:top]]\n",
        "    return closest_items"
      ],
      "metadata": {
        "id": "X2JhLiCU1NPu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entry = 'what is stochastic gradient descent ?'"
      ],
      "metadata": {
        "id": "FHVHzd-G3Sd0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " vectorizer_search(entry, top=1)[0]"
      ],
      "metadata": {
        "id": "Ir0QIX-XGE-N",
        "outputId": "e48bb7b6-753a-4193-85b1-b12f4d8f2725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As I know, Gradient Descent has three variants which are: 1- Batch Gradient Descent: processes all the training examples for each iteration of gradient descent. 2- Stochastic Gradient Descent: processes one training example per iteration. Hence, the parameters are being updated even after one iteration in which only a single example has been processed. 3- Mini Batch gradient descent: which works faster than both batch gradient descent and stochastic gradient descent. Here, b examples where b &lt; m are processed per iteration. But in some cases they use Stochastic Gradient Descent and they define a batch size for training which is what I am confused about. Also, what about Adam, AdaDelta &amp; AdaGrad, are they all mini-batch gradient descent or not?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How you can improve this approach ? "
      ],
      "metadata": {
        "id": "3AcnQSRd7XJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer* here"
      ],
      "metadata": {
        "id": "Fi4Y1vsqB_Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On pourrait mettre en place un calcul de rareté des termespour mettre en avant les similarités sur les mots rares. Cela pourrait se faire par l'ajout de poids."
      ],
      "metadata": {
        "id": "eV8KVGyl29rq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic similarity"
      ],
      "metadata": {
        "id": "hWNZJR6qYwcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are NLP methods that go further than word-by-word study, by taking into account the context of the terms. There are several methods: Word2vec, Bert.\n",
        "\n",
        "From the Sentence Transformers documentation: https://www.sbert.net/docs/pretrained_models.html choose the pre-trained model that you think is the most appropriate. Justify your choice."
      ],
      "metadata": {
        "id": "6hbMp61saeBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_transformer_model = 'multi-qa-MiniLM-L6-cos-v1'"
      ],
      "metadata": {
        "id": "gOLIblKWCSQ1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "8O6QZfgPCKMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠ To use Sentence Transformers it is recommended to activate the GPU of google colab."
      ],
      "metadata": {
        "id": "6r2keNXSeQ1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ST = SentenceTransformer(sentence_transformer_model)"
      ],
      "metadata": {
        "id": "dCTzpEkkeQAO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this algorithm to encode the data in the database"
      ],
      "metadata": {
        "id": "Ph24xTeVgTpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = MODEL_ST.encode(clean_posts[\"Clean Body\"].values, normalize_embeddings=True)"
      ],
      "metadata": {
        "id": "v-TTENiM5vn2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*If this process is slow, you can save this array in case you need to load it again*"
      ],
      "metadata": {
        "id": "TBJ0W5UygN9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(os.path.join(DATA_PATH, 'embeddings.pkl'), 'wb') as file:\n",
        "    pickle.dump(embeddings, file)"
      ],
      "metadata": {
        "id": "Qkw285npGxmY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour ouvrir le fichier .pkl dans DATA_PATH\n",
        "with open(os.path.join(DATA_PATH, 'embeddings.pkl'), 'rb') as file:\n",
        "  embeddings = pickle.load(file)"
      ],
      "metadata": {
        "id": "X-21R2qGCHlr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a function that transforms the input"
      ],
      "metadata": {
        "id": "2Hy__GOwgbIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_query(query : str) ->  np.ndarray:\n",
        "    encoded_query=MODEL_ST.encode(query)\n",
        "    return encoded_query"
      ],
      "metadata": {
        "id": "35As3cuYgRWq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which distance is most relevant to measure the distance between the input and the data?"
      ],
      "metadata": {
        "id": "xFD6pJIpgEz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here\n",
        "\n",
        "La distance 1-sim(a,b)"
      ],
      "metadata": {
        "id": "2XHL8gFRIUu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that returns a matrix containing information about the similarity between the query and the data"
      ],
      "metadata": {
        "id": "6LxvJiVKIv-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(query, sim=\"Cosine\", embeddings=embeddings):\n",
        "    #TODO\n",
        "    query_encoded = encode_query(query)\n",
        "    if sim==\"Cosine\":\n",
        "      similarity_matrix = cosine_similarity(embeddings, [query_encoded])\n",
        "    elif sim==\"Pearson\":\n",
        "      avg_q=sum(query_encoded)/len(query_encoded)\n",
        "      query_encoded=[x-avg_q for x in query_encoded]\n",
        "      embeddings_avg=[]\n",
        "      for l in embeddings:\n",
        "        avg=sum(l)/len(l)\n",
        "        l_cent=[x-avg for x in l]\n",
        "        embeddings_avg.append(l_cent)\n",
        "      embeddings_avg=np.asarray(embeddings_avg)\n",
        "      similarity_matrix = cosine_similarity(embeddings, [query_encoded])\n",
        "    return similarity_matrix.transpose()[0]"
      ],
      "metadata": {
        "id": "ZtDl3Cicf9wd"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_encoded = encode_query(query)\n",
        "avg_q=sum(query_encoded)/len(query_encoded)\n",
        "query_encoded=[x-avg_q for x in query_encoded]\n",
        "query_encoded"
      ],
      "metadata": {
        "id": "em16CSeW1NIA",
        "outputId": "b9407110-234f-4f90-f82e-c4cdb49d28d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07741857958925873,\n",
              " 0.006459381300639204,\n",
              " -0.05548104750024171,\n",
              " 0.02760871579838901,\n",
              " -0.051938058007825326,\n",
              " 0.03499161718381553,\n",
              " 0.02142656115783363,\n",
              " -0.035292250234950494,\n",
              " -0.06052632736073823,\n",
              " -0.038394575137961816,\n",
              " -0.018832099754680105,\n",
              " -0.06789186703072876,\n",
              " 0.061652607153784324,\n",
              " 0.004222695119362167,\n",
              " -0.01340544609384627,\n",
              " -0.05294752972232194,\n",
              " 0.040268066208492805,\n",
              " -0.022273316178787656,\n",
              " 0.09146999461544662,\n",
              " -0.060539950747359704,\n",
              " 0.0654906172860971,\n",
              " 0.01176275020433574,\n",
              " 0.009538180064093163,\n",
              " -0.04147497298227639,\n",
              " -0.006329981275219628,\n",
              " -0.05143829168783517,\n",
              " 0.022729960139524035,\n",
              " 0.009216468650530866,\n",
              " 0.0491639588583818,\n",
              " -0.01915402444111199,\n",
              " -0.017211550046075292,\n",
              " 0.012636609244774869,\n",
              " -0.023757486734856077,\n",
              " 0.06300238413704544,\n",
              " 0.048011104445587684,\n",
              " -0.03791676567899079,\n",
              " 0.012010566759537747,\n",
              " 0.039935181718002845,\n",
              " -0.003011741806138464,\n",
              " 0.05853757528556495,\n",
              " -0.02162999020921082,\n",
              " -0.10559571640597672,\n",
              " 0.03633467746866851,\n",
              " -0.0026519188101777518,\n",
              " 0.07003006977928787,\n",
              " 0.025029466356765322,\n",
              " -0.11297485338555664,\n",
              " -0.031396878082622,\n",
              " 0.009824767578076413,\n",
              " 0.03600673271311431,\n",
              " -0.08067630337582916,\n",
              " -0.03304854141579957,\n",
              " -0.0716258149038443,\n",
              " 0.03714279351724296,\n",
              " 0.1003356639851442,\n",
              " -0.06574025111304611,\n",
              " -0.07338135050641388,\n",
              " -0.10797450797664017,\n",
              " -0.06575111405955643,\n",
              " -0.021678903270829625,\n",
              " 0.060547190587650825,\n",
              " -0.017424288336504407,\n",
              " 0.07915979517592102,\n",
              " 0.016395300496052794,\n",
              " -0.015276079196799705,\n",
              " 0.02208922138405948,\n",
              " 0.0012865383617205832,\n",
              " -0.09527972446786255,\n",
              " 0.032278588842283774,\n",
              " -0.09919545905696243,\n",
              " 0.010991196017395547,\n",
              " -0.029031104538906522,\n",
              " -0.05740975694762559,\n",
              " 0.025342243592869334,\n",
              " 0.034563193898331214,\n",
              " 0.11089462680710464,\n",
              " -0.015163351912368247,\n",
              " 0.011173479128312161,\n",
              " 0.012393258381318143,\n",
              " -0.04169250385867448,\n",
              " 0.01928681587768703,\n",
              " -0.027900570202935644,\n",
              " -0.0018447485196778264,\n",
              " -0.004625482149738976,\n",
              " 0.04693208156121879,\n",
              " 0.036673168521057654,\n",
              " 0.0728971947540155,\n",
              " -0.014709170107115218,\n",
              " 0.032312857787739326,\n",
              " 0.012755791525970986,\n",
              " 0.06389471037281662,\n",
              " 0.010960712898205808,\n",
              " -0.09957841889964432,\n",
              " 0.026053254361878924,\n",
              " -0.09272230522738785,\n",
              " 0.06418337566746384,\n",
              " -0.014333403799999664,\n",
              " -0.06997799979554505,\n",
              " 0.05265801293743758,\n",
              " 0.022746474351417117,\n",
              " -0.006496100351531216,\n",
              " -0.004657461904306122,\n",
              " -0.05593754084812493,\n",
              " -0.08426144825326294,\n",
              " -0.09696913616763443,\n",
              " 0.07081350577963501,\n",
              " 0.04823851851714759,\n",
              " 0.01581488257242351,\n",
              " 0.024255328681003146,\n",
              " 0.0023095208310148036,\n",
              " -0.06843180315600723,\n",
              " 0.05937687946451812,\n",
              " 0.09085334731234222,\n",
              " -0.013179456945825526,\n",
              " 0.003103622570317081,\n",
              " -0.04197747739063592,\n",
              " 0.018158676903378062,\n",
              " -0.03041658284174294,\n",
              " -0.01849457727776856,\n",
              " 0.05291219321979194,\n",
              " 0.10266799373520523,\n",
              " 0.02269005669249206,\n",
              " -0.00965277677433581,\n",
              " -0.019660796169508405,\n",
              " 0.08211967987908035,\n",
              " -0.06824427949296326,\n",
              " -0.06940572815047592,\n",
              " 0.0010147903670182739,\n",
              " 0.03688953710688262,\n",
              " -0.050684803296197366,\n",
              " 0.02834881735933929,\n",
              " -0.04145510973440499,\n",
              " -0.012252863627243945,\n",
              " 0.04614809421790748,\n",
              " -0.04858779268370957,\n",
              " 0.07228850467098862,\n",
              " -0.03241738783227296,\n",
              " -0.030650158543456502,\n",
              " -0.028817857746351667,\n",
              " -0.032216125298608254,\n",
              " -0.06154111133920045,\n",
              " -0.09108620988236756,\n",
              " -0.023177511189449735,\n",
              " 0.017603929023872904,\n",
              " 0.013197959270011475,\n",
              " -0.0004886085077563014,\n",
              " -0.03558709578620286,\n",
              " 0.06035971162809043,\n",
              " -0.001814873554129311,\n",
              " 0.01696336349440723,\n",
              " -0.04411407293783517,\n",
              " 0.021360372062455706,\n",
              " 0.1066106323708406,\n",
              " -0.06441237138615936,\n",
              " -0.03538366885887475,\n",
              " -0.04953314097629876,\n",
              " 0.04782219869984298,\n",
              " 0.03073746604813247,\n",
              " -0.06421067671882004,\n",
              " -2.5201253909775236e-05,\n",
              " -0.09822615342246384,\n",
              " -0.015844543595183797,\n",
              " -0.022985465023983426,\n",
              " 0.09525199128283172,\n",
              " 0.01639666581494718,\n",
              " 0.01289978610320001,\n",
              " -0.017453753520120092,\n",
              " 0.04167920244825988,\n",
              " -0.0009300883536601152,\n",
              " 0.0013394123382492278,\n",
              " 0.0063088358004203355,\n",
              " -0.02998936096237988,\n",
              " -0.034789045472014855,\n",
              " -0.0039053784127721274,\n",
              " -0.053902664352525186,\n",
              " -0.10961546110020966,\n",
              " 0.09673858327759415,\n",
              " -0.00023171539915741346,\n",
              " -0.01208490705149264,\n",
              " 0.01968780426276832,\n",
              " -0.07770909475194306,\n",
              " 0.003559190183561138,\n",
              " 0.12124924255503326,\n",
              " 0.11123204125059753,\n",
              " -0.01019338997112603,\n",
              " 0.07347812397373825,\n",
              " -0.024675293956268735,\n",
              " 0.07106017960203796,\n",
              " -0.003087661359775969,\n",
              " -0.0536628562401423,\n",
              " 0.05767225367916732,\n",
              " -0.022052046973575063,\n",
              " -0.044126314241755914,\n",
              " 0.03675264758957534,\n",
              " -0.006148388274330803,\n",
              " -0.07336032496796936,\n",
              " 0.07352387053860336,\n",
              " 0.03724235935104995,\n",
              " 0.06540989769591003,\n",
              " -0.0385205570052752,\n",
              " 0.04185634372724204,\n",
              " -0.015692728702295728,\n",
              " -0.03351310374246926,\n",
              " -0.06367894368277878,\n",
              " 0.016215522642861895,\n",
              " 0.09671812398327499,\n",
              " 0.0366873507012239,\n",
              " -0.004520489964950987,\n",
              " 0.057413517366777946,\n",
              " -0.06692342566357941,\n",
              " -0.0037452095563897574,\n",
              " 0.0030389529277196443,\n",
              " 0.03078264078093677,\n",
              " -0.007609811742175528,\n",
              " 0.009967570062409928,\n",
              " -0.06695450948582977,\n",
              " 0.008195637594591668,\n",
              " -0.12748289959536882,\n",
              " -0.055047028828729104,\n",
              " 0.03197535579992442,\n",
              " -0.027906852905024,\n",
              " -0.060058740098346185,\n",
              " 0.015056077260207227,\n",
              " 0.0010147903670182739,\n",
              " -0.05025878282295556,\n",
              " -0.014224790167380283,\n",
              " 0.04892544714702277,\n",
              " 0.04453754318846374,\n",
              " -0.021406428087819524,\n",
              " -0.02073451796578259,\n",
              " 0.048427036832701255,\n",
              " 0.05158196656001716,\n",
              " 0.01014555884493499,\n",
              " 0.06742767883433014,\n",
              " 0.13974476499451308,\n",
              " -0.03667900072442384,\n",
              " -0.014431622010041186,\n",
              " 0.01223377497835069,\n",
              " -0.03994672851668687,\n",
              " 0.11376351756943374,\n",
              " -0.005056870766300865,\n",
              " -0.030049980748761602,\n",
              " -0.00786632591890187,\n",
              " 0.0647160698284021,\n",
              " -0.09216468142377228,\n",
              " 0.16610830171002058,\n",
              " -0.03457184987174363,\n",
              " 0.03267000136865287,\n",
              " -0.03860353039609284,\n",
              " -0.047763426918853234,\n",
              " -0.004692080095727154,\n",
              " -0.07400433825360626,\n",
              " -0.03981401877509446,\n",
              " -0.010211209897268722,\n",
              " 0.08613899243963867,\n",
              " -0.010417629164029071,\n",
              " -0.024600067306626745,\n",
              " 0.011596446726154378,\n",
              " -0.04673990340935082,\n",
              " 0.01600131938202291,\n",
              " 0.06007281584633498,\n",
              " -0.057881192434895944,\n",
              " 0.045873663257490684,\n",
              " 0.06031187517536788,\n",
              " 0.032552542965542365,\n",
              " 0.04251653967393546,\n",
              " 0.06011982900990157,\n",
              " -0.012818281669486472,\n",
              " 0.0372904342223516,\n",
              " 0.02930919906092792,\n",
              " 0.011924148406516602,\n",
              " -0.037671526093352746,\n",
              " 0.051188005935083915,\n",
              " 0.04255766687883048,\n",
              " 0.07828973127497345,\n",
              " 0.04446821926129966,\n",
              " 0.003071819767039112,\n",
              " -0.008242518771756599,\n",
              " -0.009651523214150378,\n",
              " 0.029106655027400546,\n",
              " 0.032333711962830115,\n",
              " -0.0013362950555422988,\n",
              " -0.04618093850122781,\n",
              " 0.05639715013993888,\n",
              " -0.005080133807230898,\n",
              " 0.09433785719765335,\n",
              " -0.025809615049828,\n",
              " 0.06638762248648315,\n",
              " -0.012220368851293037,\n",
              " -0.023407668937314458,\n",
              " -0.034504697788823556,\n",
              " 0.06481550527704864,\n",
              " -0.01471241110967488,\n",
              " -0.04283760594235749,\n",
              " -0.02105861077116818,\n",
              " -0.03658472480284066,\n",
              " -0.018102628309596486,\n",
              " -0.010605037343073795,\n",
              " -0.01519906813310475,\n",
              " -0.02273576999114842,\n",
              " -6.240642661244533e-05,\n",
              " 0.10191816730393082,\n",
              " 0.0034737993121704376,\n",
              " -0.07207635896312088,\n",
              " 0.016379307824801497,\n",
              " 0.03158096304131656,\n",
              " 0.010012426282893708,\n",
              " 0.08161609513653427,\n",
              " -0.04392495112525315,\n",
              " 0.087884477208983,\n",
              " 0.010231973472665837,\n",
              " 0.028805208261739306,\n",
              " -0.049233255107272576,\n",
              " -0.01421904483841748,\n",
              " 0.014684283043872407,\n",
              " -0.08367434995280594,\n",
              " -0.06685119973527283,\n",
              " -0.12220295624839157,\n",
              " 0.02642170606149345,\n",
              " 0.0010147903670182739,\n",
              " -0.01715052047776074,\n",
              " -0.018254394773710676,\n",
              " 0.012773302253018906,\n",
              " 0.037690925281178046,\n",
              " 0.018591509069930606,\n",
              " -0.036019292790759515,\n",
              " -0.015497491825688789,\n",
              " 0.014452642630468896,\n",
              " -0.03622405709730477,\n",
              " -0.029382274616826482,\n",
              " -0.010890033226777026,\n",
              " 0.023386238943468623,\n",
              " -0.005309958607275196,\n",
              " 0.04485586924446731,\n",
              " 0.010738737750481656,\n",
              " 0.000575670899972162,\n",
              " -0.06870090322600693,\n",
              " 0.02675502454830318,\n",
              " -0.015278919730652282,\n",
              " -0.013218440246153781,\n",
              " -0.0001989907029458966,\n",
              " 0.06354176891935974,\n",
              " 0.0037041128237357652,\n",
              " -0.006096803713906714,\n",
              " -0.004158397801537224,\n",
              " 0.043815082739721824,\n",
              " -0.089440562893022,\n",
              " -0.060296536553967904,\n",
              " -0.002839446897003957,\n",
              " -0.013278452810216853,\n",
              " -0.02679642209814877,\n",
              " 0.021280160974394374,\n",
              " -0.10028220819341034,\n",
              " -0.14093888657199236,\n",
              " 0.06073573498023658,\n",
              " 0.062237012069355536,\n",
              " 0.0003176264438404057,\n",
              " -0.07055930899487824,\n",
              " -0.04941685231434197,\n",
              " 0.008541161995064309,\n",
              " 0.04328941075099616,\n",
              " 0.03418816892398505,\n",
              " 0.07202783865822464,\n",
              " 0.0023137094542941368,\n",
              " 0.06773371888292938,\n",
              " -0.04438181700216622,\n",
              " -0.01138384001361222,\n",
              " -0.09445317940818161,\n",
              " 0.0177138958681932,\n",
              " -0.11925961928473801,\n",
              " -0.041917246897090386,\n",
              " -0.018308556769360013,\n",
              " 0.02087527593566089,\n",
              " -0.058994260747302484,\n",
              " 0.001171456766580074,\n",
              " 0.017392552327047877,\n",
              " -0.009814991746414611,\n",
              " 0.04287338895691543,\n",
              " -0.041061305571664285,\n",
              " -0.07308164345132202,\n",
              " 0.13267711443794875,\n",
              " -0.0016236623193511452,\n",
              " 0.11708643181217819,\n",
              " 0.07051747186077743]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"This query is there to test this search engine\"\n",
        "matrix_similarity = similarity(query, \"Pearson\", embeddings)"
      ],
      "metadata": {
        "id": "_oR0xnZCJKfc"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_similarity"
      ],
      "metadata": {
        "id": "0IWD6qALI6xx",
        "outputId": "e63c3d14-24f2-4f76-f69d-e8f5ec7bc0d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.07798918,  0.03562171,  0.00442115, ...,  0.03057431,\n",
              "       -0.03794395,  0.04464634])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do you determine which documents in the data set most closely match the input?"
      ],
      "metadata": {
        "id": "2dRGokvThOcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ordre_en_fonction_similarité(matrix_similarity):\n",
        "    #TODO\n",
        "    n=len(matrix_similarity)\n",
        "    L=[[matrix_similarity[k],k] for k in range(n)]\n",
        "    L.sort()\n",
        "    L.reverse()\n",
        "    ordre = [l[1] for l in L]\n",
        "    return ordre"
      ],
      "metadata": {
        "id": "jd1UD26VhN_9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert ordre_en_fonction_similarité([0.6, 0.8, 0.7]) == [1, 2, 0]"
      ],
      "metadata": {
        "id": "9-CoY6VUj5EE"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put it all together in a function."
      ],
      "metadata": {
        "id": "a3IBMm8HisWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def closest_semantic_doc(query, sim=\"Cosin\", embeddings=embeddings, top_n=10):\n",
        "    sim = similarity(query, sim, embeddings)\n",
        "    ordre = ordre_en_fonction_similarité(sim)[:top_n]\n",
        "    closest_posts = [clean_posts[\"Clean Body\"][k] for k in ordre]\n",
        "    return closest_posts"
      ],
      "metadata": {
        "id": "BOFygRpbifXw"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closest_semantic_doc(query, \"Pearson\")"
      ],
      "metadata": {
        "id": "X8K18c8CsaZd",
        "outputId": "b1157ce0-f834-4171-fefe-26948cd739fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This is a hyperparameter. And so this is usually approached with some sort of hyperparameters search with cross-validation, like GridSearchCV or RandomizedSearchCV. https://scikit-learn.org/stable/modules/grid_search.html',\n",
              " \"I want to understand the intent of the customer using his search queries, let's say if a customer is interested in yoga pants, he can either search for yoga pants or exercise pants or workout tights etc. Is there a model that I can use to find out all the search keywords that can be related to yoga pants? \",\n",
              " 'You could use cross validation with grid search as shown here',\n",
              " \"I have a very large dataset consisting of approximately 15,000 rows of survey data. The surveys are quantitative summaries of interviews with investors regarding their rankings of financial asset managers. They rate a manager on a scale from 1-5 and we have approximately 5 years of data for each investor on asset manager. The data is indexed as: Investor name | Manager name | Year | Rating parameter 1 | R. parameter 2 | ... | R. parameter 10 | To give you an idea, I made an example below. Currently the data is saved in an Access-database with a ton of SQL JOINT's - but I can convert the data pretty much how I want to. So compatibility is not an issue. My question is: I have a wild idea that somehow the answers are correlated between years. So maybe an increase in parameter 1 and parameter 2 is correlated with a fall in parameter 10.  I'm looking for ways to test my hypothesis without having to do it manually (this would be quite tedious). Maybe through machine-learning or subgroup discovery (I have not idea if this is correct).  Are any of you familiar with tools or algorithms that can help me test my hypotheses? Naturally I'll have to make sure my analyses are statistically significant. I'm looking very much forward hearing what you think. Example of data Buffet Holdings | Goldman Sachs AM | 2014 |1|5|5|1|4|5|1|1|1|5|  Buffet Holdings | Goldman Sachs AM | 2015 | 4 | ........| 1 |  Gates Ltd. | JP Morgan AM | 2014  | 4 | ........| 2 |  Gates Ltd. | JP Morgan AM | 2015 | 4 | ........| 3 | Buffet Holdings | JP Morgan AM | 2014 | 3 | ........| 5 |  Buffet Holdings | JP Morgan AM | 2015 | 2 | ........| 1 | \",\n",
              " 'Check these : Repository of Test Domains for Information Extraction : http://www.isi.edu/info-agents/RISE/repository.html DBpedia : http://wiki.dbpedia.org/Downloads32 (mirror) Link Updated : http://www.isi.edu/integration/RISE/  https://github.com/dbpedia/extraction-framework/wiki/The-DBpedia-Data-Set',\n",
              " 'For a phrase searching algorithm, imagine the goal is to search for a name phrase and return matched results based on a pre-defined threshold. For example, searching for \"Jon Smith\" could return \"Jon Smith\", \"Jonathan Smith\", \"Jonathan David Smith\", \"Jonathan Smith-Mikel\", \"Jonathan \\'Smith\\' Mikel\" etc. The plan is to manually choose N test cases and put them in a benchmark database. I have concern about this plan because the test cases is likely to be not exhaustive. I know there are pretty mature search engines there, so is there a test database which covers all possible cases, such as different name combinations, punctuations, symbols, etc. such that we can use this as our benchmarks instead of guessing? For example, this test database should contain all cases for \"Jon Smith\", as well as connectors such as hyphen, apostrophe, and so on.',\n",
              " 'Google AdWords.  That has absolute search volumes. ',\n",
              " \"I am not sure how many queries you'd need to perform to drown out your actual search queries, but there is already is an actual browser addon which does this. This addon is called TrackMeNot and is available to install for both Google Chrome and Firefox. More in-depth information on how this addon works can be found on their website and the whitepaper (section 3), but in short it create a dynamic list of queries based on popular search terms.\",\n",
              " 'In reference with your little found data either augment it or apply cross validation on top of it. else Look for your expected data in https://datasetsearch.research.google.com/',\n",
              " 'If I understand your query correctly,you are looking for MLFLOW where you can track your experimentation and vizualize them using APIs MLFLOW']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What methods could be used to improve the recommendations of this algorithm?"
      ],
      "metadata": {
        "id": "ouUjQrhgjEDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here"
      ],
      "metadata": {
        "id": "_v7HI2pDJk-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut changer le model ou la distance utilisée"
      ],
      "metadata": {
        "id": "1QthrPJSzUIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text clustering (BONUS)"
      ],
      "metadata": {
        "id": "fa4Ij2usk8Gb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use topic modeling techniques to identify groups of texts among our document base and classify the input to restrict the application of the proximity calculations seen previously."
      ],
      "metadata": {
        "id": "EfZcQyxLox8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LDA"
      ],
      "metadata": {
        "id": "kt9_ujt6sVMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Latent Dirichlet Allocation is a topic modeling algorithm that allows soft clustering. Soft clustering means that the LDA does not allocate an input to a cluster, but gives a probabilistic score for each identified cluster. This decomposition allows to identify topics within the documents. \n",
        "\n",
        "In order to compute this algorithm, you need to vectorize your data (you can use the one you have already done previously or make another one)."
      ],
      "metadata": {
        "id": "eH2IG1iyTxiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize document using TF-IDF\n",
        "vectorizer_lda = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit and Transform the documents\n",
        "train_data = vectorizer_lda.fit_transform(clean_posts[\"Clean Body\"].values)"
      ],
      "metadata": {
        "id": "BfpEOZYkk7kH"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use Gensim or scikit-learn to compute LDA."
      ],
      "metadata": {
        "id": "WSZ1kI3JWfTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "lda_model = LatentDirichletAllocation()\n",
        "lda_model.fit(train_data)"
      ],
      "metadata": {
        "id": "oDGFnU1CJ6_w",
        "outputId": "62d21ed9-e4ff-415d-eaad-728b44b3dc4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign a main topic to each document"
      ],
      "metadata": {
        "id": "nG_grQ93tMIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_documents = lda_model.transform(train_data)"
      ],
      "metadata": {
        "id": "ZM3cSJrWuYT_"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_documents"
      ],
      "metadata": {
        "id": "_1tsElYlD0Vj",
        "outputId": "da7a920c-6ae8-457f-ed4a-54c1c9ac26a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01560078, 0.01560078, 0.01560333, ..., 0.74946347, 0.01560078,\n",
              "        0.01560078],\n",
              "       [0.01724153, 0.01724153, 0.0172432 , ..., 0.8448239 , 0.01724153,\n",
              "        0.01724153],\n",
              "       [0.0378273 , 0.01304815, 0.01304907, ..., 0.81405751, 0.01304815,\n",
              "        0.01304815],\n",
              "       ...,\n",
              "       [0.01030455, 0.01030455, 0.01030506, ..., 0.90725489, 0.01030455,\n",
              "        0.01030455],\n",
              "       [0.01327687, 0.01327687, 0.01327737, ..., 0.84968945, 0.01327687,\n",
              "        0.01327687],\n",
              "       [0.01189033, 0.01189027, 0.0118921 , ..., 0.21305661, 0.01189051,\n",
              "        0.01189028]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_query(query, vectorizer=vectorizer_lda, lda_model=lda_model) -> int:\n",
        "    vectorized_query = vectorize_query(query, vectorizer)\n",
        "    Ltopics = lda_model.transform(vectorized_query)[0]\n",
        "    Ltopics = list(Ltopics)\n",
        "    topics =  Ltopics.index(max(Ltopics))\n",
        "    return topics"
      ],
      "metadata": {
        "id": "n86QrUuus5Bh"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_topic_query(\"Licorne dinosaure et au milieu\")"
      ],
      "metadata": {
        "id": "Bsi0oXspGe7t",
        "outputId": "7554057b-f98a-48e6-e400-fe9263fb9821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that assigns a topic to the query\n"
      ],
      "metadata": {
        "id": "oO1ZaPy6s6Uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge methods"
      ],
      "metadata": {
        "id": "ZQfMqiMpvKk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write an algorithm to merge the methods seen. Which methods to use? How can you check if they are relevant ?"
      ],
      "metadata": {
        "id": "Ll1RCEV-vVbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here"
      ],
      "metadata": {
        "id": "-vIibmanKPLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlp_search_algorithm(query,\n",
        "                         topic_documents=topic_documents,\n",
        "                         vectors=vectors,\n",
        "                         vectorizer=vectorizer,\n",
        "                         vectorizer_lda=vectorizer_lda,\n",
        "                         lda_model=lda_model,\n",
        "                         embeddings=embeddings,\n",
        "                         top_n=10\n",
        "                         )->list:\n",
        "    #TODO\n",
        "    topic=get_topic_query(\"Licorne dinosaure et au milieu\",vectorizer, lda_model)\n",
        "\n",
        "\n",
        "    return matching_posts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v2GUl3uHSJej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have a list of possible results, you can it: (you can use one of the ranking algorithms you have previously done or make up a new one)"
      ],
      "metadata": {
        "id": "mWh3EuXiT_Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank(possible_results):\n",
        "    #to_do\n",
        "    return possible_results"
      ],
      "metadata": {
        "id": "9FbEcpONT-1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incorporation in the search engine"
      ],
      "metadata": {
        "id": "pJ3vhg1kpX6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addition of metadata"
      ],
      "metadata": {
        "id": "4CDbNI-qpf3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You must now have a new set of metadata and data to add to your original index. You can load the index you had as a result of Day 2 and today's work to it. "
      ],
      "metadata": {
        "id": "yZBXyHN3MKBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load previous data \n",
        "\n",
        "#TODO "
      ],
      "metadata": {
        "id": "dK9U-NB0MctD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add the new data to the previous index"
      ],
      "metadata": {
        "id": "yV6jul7jNW7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hint : if you have changed the preprocessing function at the beginning of this notebook make sure to update the Clean Body attribute"
      ],
      "metadata": {
        "id": "HvDxs_EZKyeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adaptation to the index format\n",
        "\n",
        "Adapt your nlp search results to the index format"
      ],
      "metadata": {
        "id": "AZ8PuvLBUap8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlp_search_in_index(query,\n",
        "                        index,\n",
        "                        args):\n",
        "\n",
        "    return matching_posts\n",
        "  "
      ],
      "metadata": {
        "id": "alY_kdTOUaFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare the new searching and ranking method to the previous ones\n",
        "\n",
        "Compare in terms of efficiency (precision, completeness, speed, memory usage)"
      ],
      "metadata": {
        "id": "vPC4lvgeUpAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### merge all methods to make an efficient search algorithm"
      ],
      "metadata": {
        "id": "N_yte-oapjFW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGcqIGl8pXhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CU2e3tgiIHzr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}